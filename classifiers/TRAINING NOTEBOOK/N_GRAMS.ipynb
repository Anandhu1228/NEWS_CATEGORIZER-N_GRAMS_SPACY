{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 5, 'hathodawala': 1, 'is': 2, 'looking': 4, 'for': 0, 'job': 3}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit([\"Thor Hathodawala is looking for a job\"])\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor hathodawala': 4,\n",
       " 'hathodawala is': 1,\n",
       " 'is looking': 2,\n",
       " 'looking for': 3,\n",
       " 'for job': 0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "cv.fit([\"Thor Hathodawala is looking for a job\"])\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 9,\n",
       " 'hathodawala': 2,\n",
       " 'is': 4,\n",
       " 'looking': 7,\n",
       " 'for': 0,\n",
       " 'job': 6,\n",
       " 'thor hathodawala': 10,\n",
       " 'hathodawala is': 3,\n",
       " 'is looking': 5,\n",
       " 'looking for': 8,\n",
       " 'for job': 1}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "cv.fit([\"Thor Hathodawala is looking for a job\"])\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer(ngram_range=(1,2,3))\n",
    "# cv.fit([\"Thor Hathodawala is looking for a job\"])\n",
    "# cv.vocabulary_\n",
    "\n",
    "# # ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 12,\n",
       " 'hathodawala': 2,\n",
       " 'is': 5,\n",
       " 'looking': 9,\n",
       " 'for': 0,\n",
       " 'job': 8,\n",
       " 'thor hathodawala': 13,\n",
       " 'hathodawala is': 3,\n",
       " 'is looking': 6,\n",
       " 'looking for': 10,\n",
       " 'for job': 1,\n",
       " 'thor hathodawala is': 14,\n",
       " 'hathodawala is looking': 4,\n",
       " 'is looking for': 7,\n",
       " 'looking for job': 11}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,3))\n",
    "cv.fit([\"Thor Hathodawala is looking for a job\"])\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer(ngram_range=(3,1))\n",
    "# cv.fit([\"Thor Hathodawala is looking for a job\"])\n",
    "# cv.vocabulary_\n",
    "\n",
    "# # ERROR\n",
    "# # MIN RANGE TO MAX RANGE REQUIRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_group = [\n",
    "    \"Thor ate pizza\",\n",
    "    \"Loki is tall\",\n",
    "    \"Loki is eating pizza\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tk = []\n",
    "    for i in doc:\n",
    "        if i.is_stop or i.is_punct:\n",
    "            continue\n",
    "        filtered_tk.append(i.lemma_)\n",
    "    return \" \".join(filtered_tk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thor eat pizza'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(t_group[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loki tall'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(t_group[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loki eat pizza'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(t_group[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thor eat pizza', 'Loki tall', 'Loki eat pizza']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_group_processed = [preprocess(i) for i in t_group]\n",
    "t_group_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 7,\n",
       " 'eat': 0,\n",
       " 'pizza': 5,\n",
       " 'thor eat': 8,\n",
       " 'eat pizza': 1,\n",
       " 'loki': 2,\n",
       " 'tall': 6,\n",
       " 'loki tall': 4,\n",
       " 'loki eat': 3}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "cv.fit(t_group_processed)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform([\"Thor eat pizza\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform([\"Thor eat pizza\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform([\"Hulk eat pizza\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Watching Schr√∂dinger's Cat Die University of C...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WATCH: Freaky Vortex Opens Up In Flooded Lake</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entrepreneurs Today Don't Need a Big Budget to...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These Roads Could Recharge Your Electric Car A...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Civilian 'Guard' Fires Gun While 'Protecting' ...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12690</th>\n",
       "      <td>Coach Shakes Hands Of Imaginary Players After ...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12691</th>\n",
       "      <td>This Minivan-Sized Sea Sponge Is Thought To Be...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692</th>\n",
       "      <td>RECAP: Dramatic Eclipse Photos Don't miss the ...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12693</th>\n",
       "      <td>Richard Sherman Wants To Talk About Police Sho...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12694</th>\n",
       "      <td>Your Customers Ignore Your Emails -- How Will ...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12695 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category\n",
       "0      Watching Schr√∂dinger's Cat Die University of C...   SCIENCE\n",
       "1         WATCH: Freaky Vortex Opens Up In Flooded Lake    SCIENCE\n",
       "2      Entrepreneurs Today Don't Need a Big Budget to...  BUSINESS\n",
       "3      These Roads Could Recharge Your Electric Car A...  BUSINESS\n",
       "4      Civilian 'Guard' Fires Gun While 'Protecting' ...     CRIME\n",
       "...                                                  ...       ...\n",
       "12690  Coach Shakes Hands Of Imaginary Players After ...    SPORTS\n",
       "12691  This Minivan-Sized Sea Sponge Is Thought To Be...   SCIENCE\n",
       "12692  RECAP: Dramatic Eclipse Photos Don't miss the ...   SCIENCE\n",
       "12693  Richard Sherman Wants To Talk About Police Sho...    SPORTS\n",
       "12694  Your Customers Ignore Your Emails -- How Will ...  BUSINESS\n",
       "\n",
       "[12695 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"news_dataset.json\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "BUSINESS    4254\n",
       "SPORTS      4167\n",
       "CRIME       2893\n",
       "SCIENCE     1381\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_samples = 1500\n",
    "\n",
    "\n",
    "df_business = df[df.category==\"BUSINESS\"].sample(m_samples, random_state=10)\n",
    "df_sports = df[df.category==\"SPORTS\"].sample(m_samples, random_state=10)\n",
    "df_crime = df[df.category==\"CRIME\"].sample(m_samples, random_state=10)\n",
    "df_science = df[df.category==\"SCIENCE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "BUSINESS    1500\n",
       "SPORTS      1500\n",
       "CRIME       1500\n",
       "SCIENCE     1381\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_business,df_sports,df_crime,df_science],axis=0)\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_label'] = df['category'].map({\n",
    "    'BUSINESS': 0,\n",
    "    'SPORTS': 1, \n",
    "    'CRIME': 2, \n",
    "    'SCIENCE': 3\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>Impossible Goals and My Quest to Lose 175 Poun...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>One Way Chipotle Has Completely Revolutionized...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>Because Sexual Abuse Is The Old Normal Don‚Äôt l...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10317</th>\n",
       "      <td>The Secret To Building A Successful Business T...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8127</th>\n",
       "      <td>Nike Is The Latest Company To Ramp Up Parental...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12632</th>\n",
       "      <td>New Continent Zealandia Is Discovered Underwat...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12644</th>\n",
       "      <td>Smartphone Lovers More Likely To Forget Things...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12669</th>\n",
       "      <td>Ambitious Test On Tap For Real-Life 'Flying Sa...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12691</th>\n",
       "      <td>This Minivan-Sized Sea Sponge Is Thought To Be...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692</th>\n",
       "      <td>RECAP: Dramatic Eclipse Photos Don't miss the ...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5881 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category  \\\n",
       "4528   Impossible Goals and My Quest to Lose 175 Poun...  BUSINESS   \n",
       "3265   One Way Chipotle Has Completely Revolutionized...  BUSINESS   \n",
       "727    Because Sexual Abuse Is The Old Normal Don‚Äôt l...  BUSINESS   \n",
       "10317  The Secret To Building A Successful Business T...  BUSINESS   \n",
       "8127   Nike Is The Latest Company To Ramp Up Parental...  BUSINESS   \n",
       "...                                                  ...       ...   \n",
       "12632  New Continent Zealandia Is Discovered Underwat...   SCIENCE   \n",
       "12644  Smartphone Lovers More Likely To Forget Things...   SCIENCE   \n",
       "12669  Ambitious Test On Tap For Real-Life 'Flying Sa...   SCIENCE   \n",
       "12691  This Minivan-Sized Sea Sponge Is Thought To Be...   SCIENCE   \n",
       "12692  RECAP: Dramatic Eclipse Photos Don't miss the ...   SCIENCE   \n",
       "\n",
       "       category_label  \n",
       "4528                0  \n",
       "3265                0  \n",
       "727                 0  \n",
       "10317               0  \n",
       "8127                0  \n",
       "...               ...  \n",
       "12632               3  \n",
       "12644               3  \n",
       "12669               3  \n",
       "12691               3  \n",
       "12692               3  \n",
       "\n",
       "[5881 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df['text']\n",
    "y = df['category_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2,random_state=10,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_label\n",
       "2    1200\n",
       "0    1200\n",
       "1    1200\n",
       "3    1104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_label\n",
       "1    300\n",
       "2    300\n",
       "0    300\n",
       "3    277\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING NORMAL BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.84       300\n",
      "           1       0.88      0.86      0.87       300\n",
      "           2       0.87      0.89      0.88       300\n",
      "           3       0.93      0.83      0.88       277\n",
      "\n",
      "    accuracy                           0.87      1177\n",
      "   macro avg       0.87      0.87      0.87      1177\n",
      "weighted avg       0.87      0.87      0.87      1177\n",
      "\n",
      "0.8657604078164826\n"
     ]
    }
   ],
   "source": [
    "pipe1 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('Naive_mod',MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe1.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipe1.predict(X_test)\n",
    "\n",
    "c_report = classification_report(y_test,y_pred)\n",
    "print(c_report)\n",
    "print(pipe1.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING BAG OF WORDS N GRAM 1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.92      0.79       300\n",
      "           1       0.89      0.82      0.85       300\n",
      "           2       0.88      0.85      0.87       300\n",
      "           3       0.95      0.76      0.85       277\n",
      "\n",
      "    accuracy                           0.84      1177\n",
      "   macro avg       0.86      0.84      0.84      1177\n",
      "weighted avg       0.86      0.84      0.84      1177\n",
      "\n",
      "0.8385726423109601\n"
     ]
    }
   ],
   "source": [
    "pipe2 = Pipeline([\n",
    "    ('N_GRAM_1_2_vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('Naive_mod',MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe2.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipe2.predict(X_test)\n",
    "\n",
    "c_report = classification_report(y_test,y_pred)\n",
    "print(c_report)\n",
    "print(pipe2.score(X_test,y_test))\n",
    "\n",
    "# SLIGHT DROP IN PERFOMANCE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING BAG OF WORDS N GRAM 1,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.93      0.79       300\n",
      "           1       0.91      0.80      0.85       300\n",
      "           2       0.89      0.85      0.87       300\n",
      "           3       0.95      0.75      0.84       277\n",
      "\n",
      "    accuracy                           0.84      1177\n",
      "   macro avg       0.86      0.84      0.84      1177\n",
      "weighted avg       0.86      0.84      0.84      1177\n",
      "\n",
      "0.836873406966865\n"
     ]
    }
   ],
   "source": [
    "pipe3 = Pipeline([\n",
    "    ('N_GRAM_1_3_vectorizer', CountVectorizer(ngram_range=(1,3))),\n",
    "    ('Naive_mod',MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe3.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipe3.predict(X_test)\n",
    "\n",
    "c_report = classification_report(y_test,y_pred)\n",
    "print(c_report)\n",
    "print(pipe3.score(X_test,y_test))\n",
    "\n",
    "# SO HERE BAG OF WORDS ARE BETTER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLYING PREPROCESSING LIKE LEMMATIZATION, REMOVING PUNCTUATION, REMOVING STOP WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       300\n",
      "           1       0.90      0.88      0.89       300\n",
      "           2       0.85      0.94      0.89       300\n",
      "           3       0.92      0.85      0.89       277\n",
      "\n",
      "    accuracy                           0.88      1177\n",
      "   macro avg       0.89      0.88      0.88      1177\n",
      "weighted avg       0.89      0.88      0.88      1177\n",
      "\n",
      "0.8844519966015293\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(preprocess)\n",
    "\n",
    "x = df['text']\n",
    "y = df['category_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2,random_state=10,stratify=y)\n",
    "\n",
    "\n",
    "pipe_process = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('Naive_mod',MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_process.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipe_process.predict(X_test)\n",
    "\n",
    "c_report = classification_report(y_test,y_pred)\n",
    "print(c_report)\n",
    "print(pipe_process.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_get = {'BUSINESS': 0, 'SPORTS': 1, 'CRIME': 2, 'SCIENCE': 3}\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"news_classifier.pkl\", \"wb\") as f:\n",
    "    pickle.dump((pipe_process, t_get), f)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
